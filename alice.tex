\documentclass{report}

\usepackage{graphicx}
\usepackage[italiano]{babel}

\begin{document}

\chapter{Stato dell'arte}

\section{Speeded Up Robust Feature}

L'algoritmo SURF (Speeded Up Robust Feature) \`e un descrittore e un detector
robusto di caratteristiche locali di un'immagine.
\`E diverse volte pi\`u veloce e robusto di SIFT, il descrittore a cui si
ispira.
 SURF è stato presentato nel 2006 da Hebert Bay e ne sono state realizzate diverse implementazioni open source e commerciali:  
l'implementazione originale (commerciale) \`e scritta in c++, mentre
{\itshape JavaSurf}, {\itshape JopenSURF}, {\itshape ImageJ SURF} e {\itshape
BoofCV} sono implementazioni open source per Java.

Per cercare corrispondenze tra immagini in genere si procede con tre passi fondamentali:
\begin {enumerate}
  \item Si individuando i “punti di interesse” (ad esempio i bordi) che hanno
  la caratteristica di ripetersi, ossia possono essere ritrovati da un detector anche se cambia la prospettiva 
  di visualizzazione dell'immagine.
  \item Si descrivono i punti di interesse tramite un vettore di
  caratteristiche. Questo vettore deve essere di grandi dimensioni se si intende
  privilegiare la robustezza dell'algoritmo oppure di piccole dimensioni se
  l'obiettivo \`e la velocit\`a computazionale.
  \item Si effettua il matching tra i vettori e le immagini.
\end{enumerate}

SURF \`e nato con l'obiettivo di trovare un trade-off tra la velocit\`a
(Speeded-Up) e la robustezza (Robust).
Per l'individuazione e la descrizione dei punti di interesse SURF utilizza l'approssimazione della matrice Hessiana, 
che \`e molto accurata, e le immagini integrali, che riducono drasticamente il
tempo computazionale.

Un'immagine integrale \begin{math} I_{\Sigma}(x,y) \end{math} \`e la somma
dell'intensit\`a dei pixel compresi tra l'origine e il punto di coordinate
\begin{math} (x,y) \end{math}.
In formule:
\begin{displaymath}
I_{\Sigma}(x,y) =\sum_{i=0}^{x} \sum_{j=0}^{y} I(i,j) 
\end{displaymath}

Ottenuta l'immagine integrale bastano quattro operazioni per calcolare un'a\-rea
rettangolare di qualsiasi dimensione. Questa propriet\`a \`e sfruttata da SURF per la realizzazione di filtri di diverse dimensioni.

La matrice Hessiana permette di individuare le strutture “blob” (regioni in cui
propriet\`a come la luminosit\`a e il colore differiscono rispetto a quelle
dell'ambiente) perch\`e in quei punti il determinante (o discriminante) \`e
massimo, e di selezionare la scala dell'immagine; tuttavia le immagini con rotazioni di multipli dispari di \begin{math} \frac{\pi}{4} \end{math} perdono
ripetibilit\`a.
Le risposte blob sono memorizzate in una mappa di risposte su scale differenti.

\`E fondamentale poter trovare i punti di interesse della stessa immagine su diverse scale 
poich\`e spesso si cercano corrispondenze tra due immagini rappresentate con
scale diverse.
Lo spazio delle scale pu\`o essere rappresentato come una piramide; con i
metodi tradizionali (ad esempio SIFT) l'immagine viene continuamente ridimensionata mentre SURF ridimensiona solo il filtro: il calcolo delle scale 
pu\`o essere eseguito con attivit\`a in parallelo guadagnando velocit\`a
computazionale mentre con SIFT l'immagine ad ogni livello di scala dipende da quella precedente, per cui la computazione \`e sequenziale. La differenza 
tra i metodi SIFT e SURF \`e mostrata in Figura 1.1.

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.2]{Figure/Figura1_1.png}
\caption{A sinistra l'approccio SIFT (ridimensionamento
dell'immagine), a destra il metodo SURF (ridimensionamento del filtro).}
\end{figure}

Il numero di punti di interesse individuati varia con la scala: chiaramente
maggiore \`e la scala minore \`e il numero dei punti di interesse individuati, come mostrato nel seguente diagramma:

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.35]{Figure/Figura1_2.png}
\caption{Diagramma dei punti di interessi individuati in rapporto alla scala}
\end{figure}

I descrittori SURF descrivono la distribuzione dell'intensit\`a del contenuto (pixel?) nell'intorno del punto 
di interesse in modo simile a SIFT. Si costruisce la distribuzione di primo ordine delle risposte della 
wavelet Haar nelle direzioni x e y e anche in questo caso si utilizzano le immagini integrali per aumentare la velocit\`a.
 
Inizialmente si cerca un'orientazione riproducibile e indipendente dalla rotazione dell'immagine: 
la si ottiene dalle informazioni contenute in una regione circolare intorno al punto di interesse; 
in seguito si costruisce una regione quadrata allineata con l'orientamento trovato e si estrae 
il descrittore SURF composto da 64 componenti; infine si procede con il matching tra le immagini. 
Per quest'ultimo step si cerca di risparmiare tempo distinguendo i blob scuri da quelli chiari e confrontando solo i blob 
che hanno lo stesso tipo di contrasto.

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.4]{Figure/Figura1_3.png}
\caption{Due blob con contrasti differenti non sono presi in considerazione per il matching}
\end{figure}

\section{Active Shape Models}

I metodi basati su modello utilizzano una forma base che rappresenta
l'immagine; questa viene utilizzata per trovare la  miglior corrispondenza tra
il modello e una nuova immagine.
Questo approccio “top-down” \`e pi\`u semplice e meno soggetto a errori di quello “bottom-up” nel quale l'immagine 
viene analizzata per individuare particolari strutture e punti di interesse che la caratterizzano.

Gli Active shape models (ASMs) sono modelli statistici delle forme di
oggetti che vengono iterativamente deformati fino ad adattarsi alle nuove
immagini.
Sono stati sviluppati da Tim Cootes e Chris Taylor nel 1995.

Il modello ASM \`e costruito in base all'analisi di un training set di immagini
d'esempio e la forma dell'oggetto \`e rappresentato da un insieme di punti controllati dal modello.

L'algoritmo ASM alterna due passi fondamentali:
\begin {enumerate}
  \item La generazione della forma base analizzando l'intorno di ogni punto
  per un miglior posizionamento del punto stesso.
  \item L'adattamento della forma al modello di distibuzione dei punti.
\end{enumerate}

Per il primo passo \`e necessario che l'algoritmo individui dei punti di
riferimento sempre presenti nelle immagini appartenenti al training set: ci\`o
implica che il training set deve contenere la stessa tipologia di oggetti e che questi ultimi abbiano una forma tale da prevedere 
punti di riferimenti ben distinti; ASMs non \`e adatto a immagini di oggetti
amorfi.

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.4]{Figure/Figura1_4.png}
\caption{I punti di riferimento trovati nell'immagine di un volto}
\end{figure}


\end{document}